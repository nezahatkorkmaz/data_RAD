{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch deepspeed transformers datasets accelerate wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiZhKxkRbpii",
        "outputId": "15550906-9393-48b3-cd82-351e192a6c98"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.16.4.tar.gz (1.4 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepspeed) (0.8.1)\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.1.0)\n",
            "Collecting ninja (from deepspeed)\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepspeed) (4.67.1)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from deepspeed) (12.570.86)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.16.4-py3-none-any.whl size=1562647 sha256=475b715f9b9473684e655d2749be5d453d5400506129eed1ac56f4652785d26c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/6c/e5/ccad75c8ade9cb21e74721affd6d17820b1806249aac34f7f0\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: hjson, xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, deepspeed\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed datasets-3.3.2 deepspeed-0.16.4 dill-0.3.8 hjson-3.1.0 multiprocess-0.70.16 ninja-1.11.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUXjA29laxGH",
        "outputId": "7b535bf6-2336-441d-d733-f13817e6e7d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data_RAD'...\n",
            "remote: Enumerating objects: 402, done.\u001b[K\n",
            "remote: Counting objects: 100% (402/402), done.\u001b[K\n",
            "remote: Compressing objects: 100% (394/394), done.\u001b[K\n",
            "remote: Total 402 (delta 4), reused 401 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (402/402), 18.05 MiB | 16.04 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "(verisetleri is not a valid attribute name: .gitattributes:8\n",
            "/content/data_RAD\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nezahatkorkmaz/data_RAD.git\n",
        "%cd data_RAD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/data_RAD\n",
        "!ls -R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv2UoXkYchEz",
        "outputId": "fcef22ea-10b1-4c78-868e-643266a4f9d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data_RAD\n",
            ".:\n",
            "dataset  Fine_Tune  llava  README  README.md  Veri_Onisleme\n",
            "\n",
            "./dataset:\n",
            "images\tturkce_med_llava_veriseti.json\n",
            "\n",
            "./dataset/images:\n",
            "synpic100132.jpg  synpic23631.jpg  synpic31400.jpg  synpic40520.jpg  synpic51709.jpg\n",
            "synpic100176.jpg  synpic23648.jpg  synpic31467.jpg  synpic40596.jpg  synpic51774.jpg\n",
            "synpic100228.jpg  synpic23803.jpg  synpic31757.jpg  synpic41050.jpg  synpic51872.jpg\n",
            "synpic12210.jpg   synpic23989.jpg  synpic31916.jpg  synpic41119.jpg  synpic51926.jpg\n",
            "synpic13385.jpg   synpic24220.jpg  synpic31928.jpg  synpic41325.jpg  synpic52248.jpg\n",
            "synpic15006.jpg   synpic24248.jpg  synpic31955.jpg  synpic41667.jpg  synpic52282.jpg\n",
            "synpic16170.jpg   synpic24319.jpg  synpic31962.jpg  synpic41772.jpg  synpic52732.jpg\n",
            "synpic16174.jpg   synpic24350.jpg  synpic32012.jpg  synpic41788.jpg  synpic52767.jpg\n",
            "synpic16221.jpg   synpic24390.jpg  synpic32081.jpg  synpic42157.jpg  synpic52828.jpg\n",
            "synpic16407.jpg   synpic24424.jpg  synpic32084.jpg  synpic42182.jpg  synpic52932.jpg\n",
            "synpic16520.jpg   synpic24538.jpg  synpic32108.jpg  synpic42202.jpg  synpic52951.jpg\n",
            "synpic16810.jpg   synpic24729.jpg  synpic32136.jpg  synpic42210.jpg  synpic52988.jpg\n",
            "synpic17145.jpg   synpic24878.jpg  synpic32727.jpg  synpic42245.jpg  synpic53033.jpg\n",
            "synpic17153.jpg   synpic24967.jpg  synpic32933.jpg  synpic42290.jpg  synpic53097.jpg\n",
            "synpic17664.jpg   synpic25105.jpg  synpic32962.jpg  synpic42307.jpg  synpic53207.jpg\n",
            "synpic17675.jpg   synpic25534.jpg  synpic32970.jpg  synpic42805.jpg  synpic53228.jpg\n",
            "synpic17693.jpg   synpic25587.jpg  synpic32981.jpg  synpic42951.jpg  synpic53287.jpg\n",
            "synpic17738.jpg   synpic25758.jpg  synpic33102.jpg  synpic43433.jpg  synpic53574.jpg\n",
            "synpic17848.jpg   synpic25821.jpg  synpic33226.jpg  synpic43609.jpg  synpic53635.jpg\n",
            "synpic18250.jpg   synpic26158.jpg  synpic33302.jpg  synpic43648.jpg  synpic53816.jpg\n",
            "synpic18319.jpg   synpic26248.jpg  synpic33331.jpg  synpic44865.jpg  synpic53867.jpg\n",
            "synpic18461.jpg   synpic26413.jpg  synpic33378.jpg  synpic44995.jpg  synpic53978.jpg\n",
            "synpic18651.jpg   synpic26697.jpg  synpic33422.jpg  synpic45039.jpg  synpic54004.jpg\n",
            "synpic18896.jpg   synpic26764.jpg  synpic33429.jpg  synpic45115.jpg  synpic54391.jpg\n",
            "synpic19114.jpg   synpic26925.jpg  synpic33481.jpg  synpic45162.jpg  synpic54610.jpg\n",
            "synpic19118.jpg   synpic27013.jpg  synpic33689.jpg  synpic45364.jpg  synpic54795.jpg\n",
            "synpic19232.jpg   synpic27047.jpg  synpic33844.jpg  synpic45544.jpg  synpic54802.jpg\n",
            "synpic19477.jpg   synpic27142.jpg  synpic33889.jpg  synpic45557.jpg  synpic54823.jpg\n",
            "synpic19605.jpg   synpic27198.jpg  synpic33892.jpg  synpic45610.jpg  synpic55245.jpg\n",
            "synpic19782.jpg   synpic27277.jpg  synpic34017.jpg  synpic45634.jpg  synpic55286.jpg\n",
            "synpic19853.jpg   synpic27402.jpg  synpic34054.jpg  synpic45699.jpg  synpic55317.jpg\n",
            "synpic20208.jpg   synpic27576.jpg  synpic34449.jpg  synpic45914.jpg  synpic55464.jpg\n",
            "synpic20260.jpg   synpic27597.jpg  synpic34515.jpg  synpic46062.jpg  synpic55583.jpg\n",
            "synpic20375.jpg   synpic27601.jpg  synpic34713.jpg  synpic46539.jpg  synpic55948.jpg\n",
            "synpic20626.jpg   synpic27646.jpg  synpic34836.jpg  synpic46720.jpg  synpic56061.jpg\n",
            "synpic21028.jpg   synpic27655.jpg  synpic34854.jpg  synpic46764.jpg  synpic56116.jpg\n",
            "synpic21037.jpg   synpic27985.jpg  synpic34922.jpg  synpic46943.jpg  synpic56344.jpg\n",
            "synpic21042.jpg   synpic28180.jpg  synpic34947.jpg  synpic46976.jpg  synpic56388.jpg\n",
            "synpic21044.jpg   synpic28210.jpg  synpic35155.jpg  synpic47020.jpg  synpic56422.jpg\n",
            "synpic21410.jpg   synpic28277.jpg  synpic35191.jpg  synpic47191.jpg  synpic56799.jpg\n",
            "synpic21604.jpg   synpic28355.jpg  synpic35356.jpg  synpic47196.jpg  synpic56841.jpg\n",
            "synpic21700.jpg   synpic28378.jpg  synpic35914.jpg  synpic47356.jpg  synpic57237.jpg\n",
            "synpic21734.jpg   synpic28569.jpg  synpic37275.jpg  synpic47737.jpg  synpic57317.jpg\n",
            "synpic21776.jpg   synpic28602.jpg  synpic37605.jpg  synpic47783.jpg  synpic57368.jpg\n",
            "synpic21902.jpg   synpic28695.jpg  synpic38069.jpg  synpic47964.jpg  synpic57520.jpg\n",
            "synpic21995.jpg   synpic28718.jpg  synpic38263.jpg  synpic47974.jpg  synpic57813.jpg\n",
            "synpic22020.jpg   synpic28987.jpg  synpic38531.jpg  synpic48091.jpg  synpic57935.jpg\n",
            "synpic22037.jpg   synpic29048.jpg  synpic38630.jpg  synpic48122.jpg  synpic58261.jpg\n",
            "synpic22097.jpg   synpic29219.jpg  synpic38858.jpg  synpic48714.jpg  synpic58547.jpg\n",
            "synpic22156.jpg   synpic29263.jpg  synpic39086.jpg  synpic48749.jpg  synpic58902.jpg\n",
            "synpic22286.jpg   synpic29265.jpg  synpic39088.jpg  synpic49027.jpg  synpic59126.jpg\n",
            "synpic22310.jpg   synpic29771.jpg  synpic39141.jpg  synpic49381.jpg  synpic59131.jpg\n",
            "synpic22684.jpg   synpic29795.jpg  synpic39240.jpg  synpic49862.jpg  synpic59356.jpg\n",
            "synpic22791.jpg   synpic30215.jpg  synpic39301.jpg  synpic49914.jpg  synpic59536.jpg\n",
            "synpic22794.jpg   synpic30273.jpg  synpic39460.jpg  synpic50848.jpg  synpic59935.jpg\n",
            "synpic22828.jpg   synpic30324.jpg  synpic39532.jpg  synpic50943.jpg  synpic60096.jpg\n",
            "synpic22874.jpg   synpic31116.jpg  synpic39757.jpg  synpic50949.jpg  synpic60254.jpg\n",
            "synpic22967.jpg   synpic31217.jpg  synpic40096.jpg  synpic50958.jpg  synpic60423.jpg\n",
            "synpic22982.jpg   synpic31232.jpg  synpic40272.jpg  synpic50962.jpg  synpic60543.jpg\n",
            "synpic23008.jpg   synpic31248.jpg  synpic40314.jpg  synpic51212.jpg  synpic60703.jpg\n",
            "synpic23053.jpg   synpic31256.jpg  synpic40426.jpg  synpic51282.jpg  synpic60831.jpg\n",
            "synpic23130.jpg   synpic31259.jpg  synpic40464.jpg  synpic51383.jpg  synpic676.jpg\n",
            "synpic23571.jpg   synpic31394.jpg  synpic40500.jpg  synpic51426.jpg  synpic9872.jpg\n",
            "\n",
            "./Fine_Tune:\n",
            "fine_tune_lora.ipynb  finetune_lora_med.sh  train_med.py\n",
            "\n",
            "./llava:\n",
            "CODE_OF_CONDUCT.md  docs\t      images   llava\t       README.md    SUPPORT.md\n",
            "data\t\t    download_data.sh  LICENSE  pyproject.toml  SECURITY.md\n",
            "\n",
            "./llava/data:\n",
            "eval\n",
            "\n",
            "./llava/data/eval:\n",
            "llava_med_eval_qa50_qa.jsonl\n",
            "\n",
            "./llava/docs:\n",
            "llava_med_performance.md\n",
            "\n",
            "./llava/images:\n",
            "llava_logo.png\t\t     llava_med_chat.png     llava_med_pipeline.png\n",
            "llava_med_chat_example1.png  llava_med_dataset.png  llava_med_vqa.png\n",
            "llava_med_chat_example2.png  llava_med_logo.png\n",
            "\n",
            "./llava/llava:\n",
            "constants.py  conversation.py  eval  __init__.py  mm_utils.py  model  serve  utils.py\n",
            "\n",
            "./llava/llava/eval:\n",
            "eval_multimodal_chat_gpt_score.py  llm.py  model_vqa.py  summarize_gpt_review.py  util.py\n",
            "\n",
            "./llava/llava/model:\n",
            "builder.py  __init__.py  language_model  llava_arch.py\tmultimodal_encoder  multimodal_projector\n",
            "\n",
            "./llava/llava/model/language_model:\n",
            "llava_mistral.py\n",
            "\n",
            "./llava/llava/model/multimodal_encoder:\n",
            "builder.py  clip_encoder.py\n",
            "\n",
            "./llava/llava/model/multimodal_projector:\n",
            "builder.py\n",
            "\n",
            "./llava/llava/serve:\n",
            "cli.py\t       examples\t\t     __init__.py      register_worker.py\n",
            "controller.py  gradio_web_server.py  model_worker.py  test_message.py\n",
            "\n",
            "./llava/llava/serve/examples:\n",
            "bio_patch.png\t     med_img_1.png    synpic42202.jpg  xy_chromosome.jpg\n",
            "extreme_ironing.jpg  synpic32933.jpg  waterview.jpg\n",
            "\n",
            "./Veri_Onisleme:\n",
            "'ham veri'\t       'llava formatına getirilmiş veri'   veriseti_dönüştürücü.py\n",
            " id_karsilastirici.py   normalizasyon.py\n",
            "\n",
            "'./Veri_Onisleme/ham veri':\n",
            "imgid2idx.json\ttestset.json  trainset.json\n",
            "\n",
            "'./Veri_Onisleme/llava formatına getirilmiş veri':\n",
            "testset_llava.json  trainset_llava.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 Google Colab için Gerekli Ayarlar\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# GPU kontrolü\n",
        "!nvidia-smi\n",
        "\n",
        "# Hugging Face giriş yap\n",
        "!huggingface-cli login\n",
        "# hf_lNzsxxx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsTzKmjVjt7W",
        "outputId": "dd01e81f-f88e-4ab3-bc32-9ef2af481fba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar  9 11:06:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   52C    P8             17W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `tezy` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `tezy`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1957gvImePU",
        "outputId": "ad769159-4993-41f9-d352-f741758f6838"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdataset\u001b[0m/  \u001b[01;34mFine_Tune\u001b[0m/  \u001b[01;34mllava\u001b[0m/  README  README.md  \u001b[01;34mVeri_Onisleme\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l Fine_Tune/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpbvNTCAm0c9",
        "outputId": "0b0f3e4c-94a3-41de-c4d6-06e97e807c49"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 84\n",
            "-rw-r--r-- 1 root root 61727 Mar  9 11:06 fine_tune_lora.ipynb\n",
            "-rw-r--r-- 1 root root  1681 Mar  9 12:12 finetune_lora_med.sh\n",
            "-rw-r--r-- 1 root root  1258 Mar  9 12:19 fine_tune_med.sh\n",
            "-rw-r--r-- 1 root root   532 Mar  9 12:14 test_model.sh\n",
            "-rw-r--r-- 1 root root  2374 Mar  9 12:12 test.py\n",
            "-rwxr-xr-x 1 root root  3063 Mar  9 12:18 \u001b[0m\u001b[01;32mtrain_med.py\u001b[0m*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/microsoft/llava-med-v1.5-mistral-7b\n",
        "!cd llava-med-v1.5-mistral-7b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfRA8jez-Lc2",
        "outputId": "ae07b4db-d5ef-47ae-d0bc-aa4c85bb38fc"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'llava-med-v1.5-mistral-7b' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvbwZRIIErgt",
        "outputId": "1d081813-a744-4554-992e-a6543e868047"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-2seh45de\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-2seh45de\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 94ae1ba5b55e79ba766582de8a199d8ccf24a021\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.50.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.50.0.dev0) (2025.1.31)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.50.0.dev0-py3-none-any.whl size=10877688 sha256=0779670cd61993a508831b1f71dfc4e76da910727f3b39cae93082b6e026c0f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-228l_6d9/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "Successfully installed transformers-4.50.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x /content/data_RAD/Fine_Tune/train_med.py\n",
        "!chmod +x /content/data_RAD/Fine_Tune/test.py\n",
        "!chmod +x /content/data_RAD/Fine_Tune/fine_tune_med.sh\n",
        "!chmod +x /content/data_RAD/Fine_Tune/test_model.sh"
      ],
      "metadata": {
        "id": "JJoAAfrZmEC3"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/\\r$//' /content/data_RAD/Fine_Tune/fine_tune_med.sh\n",
        "!sed -i 's/\\r$//' /content/data_RAD/Fine_Tune/test_model.sh"
      ],
      "metadata": {
        "id": "1At8p9bBchK6"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/data_RAD/Fine_Tune/fine_tune_med.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYWhrUkr1IpO",
        "outputId": "ed276e60-4a0a-4e02-f28a-16117df9f41d"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ export PYTHONIOENCODING=utf-8\n",
            "+ PYTHONIOENCODING=utf-8\n",
            "+ export HF_HOME=/root/.cache/huggingface\n",
            "+ HF_HOME=/root/.cache/huggingface\n",
            "+ export TRANSFORMERS_CACHE=/root/.cache/huggingface/transformers\n",
            "+ TRANSFORMERS_CACHE=/root/.cache/huggingface/transformers\n",
            "+ export WANDB_DISABLED=true\n",
            "+ WANDB_DISABLED=true\n",
            "+ export PYTHONPATH=/env/python:/content/data_RAD/llava\n",
            "+ PYTHONPATH=/env/python:/content/data_RAD/llava\n",
            "+ echo '📂 Çalışma dizinine gidiliyor...'\n",
            "📂 Çalışma dizinine gidiliyor...\n",
            "+ cd /content/data_RAD/Fine_Tune\n",
            "+ echo '🚀 Fine-tuning başlatılıyor...'\n",
            "🚀 Fine-tuning başlatılıyor...\n",
            "+ echo '🔎 Kullanılan Deepspeed Config: /content/data_RAD/llava/scripts/zero3.json'\n",
            "🔎 Kullanılan Deepspeed Config: /content/data_RAD/llava/scripts/zero3.json\n",
            "+ deepspeed train_med.py --model_name_or_path /content/data_RAD/llava-med-v1.5-mistral-7b --model_base mistralai/Mistral-7B-Instruct-v0.2 --data_path /content/data_RAD/dataset/turkce_med_llava_veriseti.json --image_folder /content/data_RAD/dataset/images --output_dir /content/data_RAD/checkpoints/llava-med-finetune --num_train_epochs 3 --per_device_train_batch_size 4 --learning_rate 2e-4 --local_rank 0\n",
            "+ tee fine_tune_log.txt\n",
            "[2025-03-09 14:30:20,807] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2025-03-09 14:30:24.738769: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-03-09 14:30:24.758421: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741530624.781235   61374 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741530624.788347   61374 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-09 14:30:24.811900: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025-03-09 14:30:27,698] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "Detected VISIBLE_DEVICES=0: setting --include=localhost:0\n",
            "[2025-03-09 14:30:27,699] [INFO] [runner.py:607:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train_med.py --model_name_or_path /content/data_RAD/llava-med-v1.5-mistral-7b --model_base mistralai/Mistral-7B-Instruct-v0.2 --data_path /content/data_RAD/dataset/turkce_med_llava_veriseti.json --image_folder /content/data_RAD/dataset/images --output_dir /content/data_RAD/checkpoints/llava-med-finetune --num_train_epochs 3 --per_device_train_batch_size 4 --learning_rate 2e-4 --local_rank 0\n",
            "[2025-03-09 14:30:29,492] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2025-03-09 14:30:33.402495: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741530633.423692   61477 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741530633.430205   61477 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.22.3-1+cuda12.5\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.22.3-1\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:139:main] 0 NCCL_VERSION=2.22.3-1\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.22.3-1+cuda12.5\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.22.3-1\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:164:main] dist_world_size=1\n",
            "[2025-03-09 14:30:36,395] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2025-03-09 14:30:36,396] [INFO] [launch.py:256:main] process 61579 spawned with command: ['/usr/bin/python3', '-u', 'train_med.py', '--local_rank=0', '--model_name_or_path', '/content/data_RAD/llava-med-v1.5-mistral-7b', '--model_base', 'mistralai/Mistral-7B-Instruct-v0.2', '--data_path', '/content/data_RAD/dataset/turkce_med_llava_veriseti.json', '--image_folder', '/content/data_RAD/dataset/images', '--output_dir', '/content/data_RAD/checkpoints/llava-med-finetune', '--num_train_epochs', '3', '--per_device_train_batch_size', '4', '--learning_rate', '2e-4', '--local_rank', '0']\n",
            "[2025-03-09 14:30:38,151] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "2025-03-09 14:30:42.420591: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741530642.441954   61579 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741530642.448509   61579 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "✅ [INIT] LLaVA kodları yolu eklendi: /content/data_RAD/llava\n",
            "📂 Model /content/data_RAD/llava-med-v1.5-mistral-7b yükleniyor...\n",
            "You are using a model of type llava to instantiate a model of type llava_mistral. This is not supported for all configurations of models and can yield errors.\n",
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.13s/it]\n",
            "✅ Model eğitim için hazır!\n",
            "📂 Veri Seti: /content/data_RAD/dataset/turkce_med_llava_veriseti.json\n",
            "📸 Görseller: /content/data_RAD/dataset/images\n",
            "📍 Çıktı Klasörü: /content/data_RAD/checkpoints/llava-med-finetune\n",
            "🚀 Epoch 1/3 başladı...\n",
            "🎯 Epoch 1 tamamlandı!\n",
            "🚀 Epoch 2/3 başladı...\n",
            "🎯 Epoch 2 tamamlandı!\n",
            "🚀 Epoch 3/3 başladı...\n",
            "🎯 Epoch 3 tamamlandı!\n",
            "💾 Model kaydediliyor: /content/data_RAD/checkpoints/llava-med-finetune\n",
            "✅ Model başarıyla kaydedildi!\n",
            "[2025-03-09 14:32:08,408] [INFO] [launch.py:351:main] Process 61579 exits successfully.\n",
            "+ '[' 0 -eq 0 ']'\n",
            "+ echo '✅ Fine-tuning başarıyla tamamlandı!'\n",
            "✅ Fine-tuning başarıyla tamamlandı!\n",
            "+ ls -lh /content/data_RAD/checkpoints/llava-med-finetune\n",
            "total 15G\n",
            "-rw-r--r-- 1 root root 1.5K Mar  9 14:30 config.json\n",
            "-rw-r--r-- 1 root root  116 Mar  9 14:30 generation_config.json\n",
            "-rw-r--r-- 1 root root 4.7G Mar  9 14:31 model-00001-of-00004.safetensors\n",
            "-rw-r--r-- 1 root root 4.7G Mar  9 14:31 model-00002-of-00004.safetensors\n",
            "-rw-r--r-- 1 root root 4.6G Mar  9 14:32 model-00003-of-00004.safetensors\n",
            "-rw-r--r-- 1 root root 251M Mar  9 14:32 model-00004-of-00004.safetensors\n",
            "-rw-r--r-- 1 root root  72K Mar  9 14:32 model.safetensors.index.json\n",
            "-rw-r--r-- 1 root root  552 Mar  9 14:32 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 1.5K Mar  9 14:32 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root 3.4M Mar  9 14:32 tokenizer.json\n",
            "-rw-r--r-- 1 root root 482K Mar  9 14:32 tokenizer.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G08VoAsI3ENi",
        "outputId": "708ca1b1-ad86-43c6-b7b4-5596ce67468c"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/data_RAD /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fsjNtblVKoq",
        "outputId": "b43aaa14-d6cc-45d7-84b3-ea5952f6ff05"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XZKhAJzbVqD3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}