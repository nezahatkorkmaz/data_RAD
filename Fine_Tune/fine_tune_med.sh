#!/bin/bash

set -e  # Hata oluÅŸursa script'i durdur
set -x  # KomutlarÄ± Ã§alÄ±ÅŸtÄ±rÄ±rken gÃ¶ster

export PYTHONIOENCODING=utf-8
export HF_HOME="/root/.cache/huggingface"
export TRANSFORMERS_CACHE="/root/.cache/huggingface/transformers"
export WANDB_DISABLED=true
export PYTHONPATH=$PYTHONPATH:/content/data_RAD/llava  # LLaVA'nÄ±n yolu

# Ã‡alÄ±ÅŸma dizinine gidiyoruz
echo "ğŸ“‚ Ã‡alÄ±ÅŸma dizinine gidiliyor..."
cd "/content/data_RAD/Fine_Tune" || { echo "ğŸš¨ Dizine gidilemedi!"; exit 1; }

echo "ğŸš€ Fine-tuning baÅŸlatÄ±lÄ±yor..."
echo "ğŸ” KullanÄ±lan Deepspeed Config: /content/data_RAD/llava/scripts/zero3.json"

# EÄŸitim baÅŸlatÄ±lÄ±yor
deepspeed train_med.py \
    --model_name_or_path "/content/data_RAD/llava-med-v1.5-mistral-7b" \
    --model_base "mistralai/Mistral-7B-Instruct-v0.2" \
    --data_path "/content/data_RAD/dataset/turkce_med_llava_veriseti.json" \
    --image_folder "/content/data_RAD/dataset/images" \
    --output_dir "/content/data_RAD/checkpoints/llava-med-finetune" \
    --num_train_epochs 3 \
    --per_device_train_batch_size 4 \
    --learning_rate 2e-4 \
    --local_rank 0  2>&1 | tee fine_tune_log.txt  # LoglarÄ± kaydet

if [ $? -eq 0 ]; then
    echo "âœ… Fine-tuning baÅŸarÄ±yla tamamlandÄ±!"
    ls -lh /content/data_RAD/checkpoints/llava-med-finetune  # Checkpoint dosyalarÄ±nÄ± gÃ¶ster

else
    echo "ğŸš¨ Fine-tuning sÄ±rasÄ±nda hata oluÅŸtu!"
    exit 1
fi
